{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CharacterBased Music Generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5juSWKWU_Jj5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Import**"
      ]
    },
    {
      "metadata": {
        "id": "MCDeokrB_Lg-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install keras-rl\n",
        "!pip install music21"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eIzEgKuy_MG3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "from music21 import stream, converter, instrument, note, chord\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import CuDNNLSTM\n",
        "from keras.layers import Activation\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oEnu0dyzAU9p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Data Import**"
      ]
    },
    {
      "metadata": {
        "id": "WBjIsYHPAZwR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "fileNames = [];\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  fileNames.append(fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BC3y6kgR_VC9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Data Processing**"
      ]
    },
    {
      "metadata": {
        "id": "IfJyORUZ_tu9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Parse all notes & chords in songs into strings\n",
        "'''\n",
        "notes = []\n",
        "\n",
        "for file in fileNames:\n",
        "  midi = converter.parse(file)\n",
        "  print(\"Parsing {}\".format(file))\n",
        "  \n",
        "  notes_to_parse = None\n",
        "  try: \n",
        "    # file has instrument\n",
        "    s2 = instrument.partitionByInstrument(midi)\n",
        "    notes_to_parse = s2.parts[0].recurse()\n",
        "  except: # file has notes in a flat structure\n",
        "    notes_to_parse = midi.flat.notes\n",
        "\n",
        "  for element in notes_to_parse:\n",
        "    if isinstance(element, note.Note):\n",
        "      notes.append(str(element.pitch))\n",
        "    elif isinstance(element, chord.Chord):\n",
        "      notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "      \n",
        "print(notes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PYxX9e_sBy3a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Create dictionary for notes\n",
        "'''\n",
        "pitchnames = sorted(set(item for item in notes))\n",
        "dictionary = dict((note, number) for number,note in enumerate(pitchnames))\n",
        "\n",
        "print(dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r3tl6fxeEuwg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Prepare training data\n",
        "'''\n",
        "WINDOW = 100\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in range(0, len(notes) - WINDOW, 1):\n",
        "  x = notes[i:i + WINDOW]\n",
        "  y = notes[i + WINDOW]\n",
        "  X.append([dictionary[c] for c in x])\n",
        "  Y.append(dictionary[y])\n",
        "  \n",
        "dataSetSize = len(X)\n",
        "\n",
        "X = np.reshape(X, (dataSetSize, WINDOW, 1))\n",
        "X = X / float(len(dictionary))\n",
        "\n",
        "print(Y)\n",
        "Y = np_utils.to_categorical(Y)\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dYxEnIjWGs01",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Model Definition**"
      ]
    },
    {
      "metadata": {
        "id": "6HSMQ84tGu2y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(CuDNNLSTM(512, input_shape=(WINDOW, 1), return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(CuDNNLSTM(512))\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(len(dictionary)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wC77BZszH4kV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Model Training**"
      ]
    },
    {
      "metadata": {
        "id": "fMhi25A4H6eU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "weights_filename = 'model_weights.h5f'\n",
        "checkpoint = ModelCheckpoint(\n",
        "    weights_filename,\n",
        "    monitor='loss',\n",
        "    verbose=0\n",
        ")\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "model.fit(\n",
        "    X,\n",
        "    Y,\n",
        "    epochs=200,\n",
        "    batch_size=200,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4wo_FFRLDwe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Music Generation**"
      ]
    },
    {
      "metadata": {
        "id": "_4FNW3OmLFmd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Generate song\n",
        "'''\n",
        "\n",
        "songlength = 500\n",
        "\n",
        "seed = np.random.randint(0, len(X) - 1)\n",
        "reverse_dictionary = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "currentSequence = X[seed][:]\n",
        "generatedSong = []\n",
        "\n",
        "for i in range(songlength):\n",
        "  x = np.reshape(currentSequence, (1, len(currentSequence,), 1))\n",
        "  x = x / float(len(dictionary))\n",
        "  \n",
        "  p = model.predict(x, verbose=0)\n",
        "  \n",
        "  index = np.argmax(p)\n",
        "  result = reverse_dictionary[index]\n",
        "  generatedSong.append(result)\n",
        "  \n",
        "  currentSequence = np.append(currentSequence, index)\n",
        "  currentSequence = currentSequence[1 : len(currentSequence)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXlh37HzNJzJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Convert to midi\n",
        "'''\n",
        "\n",
        "offset = 0\n",
        "output_notes = []\n",
        "\n",
        "for sequence in generatedSong:\n",
        "  #if sequence is chord\n",
        "  if('.' in sequence) or sequence.isdigit():\n",
        "    notes_in_chord = sequence.split('.')\n",
        "    notes = []\n",
        "    for n in notes_in_chord:\n",
        "      new_n = note.Note(int(n))\n",
        "      new_n.storedInstrument = instrument.Piano()\n",
        "      notes.append(new_n)\n",
        "    new_chord = chord.Chord(notes)\n",
        "    new_chord.offset = offset\n",
        "    output_notes.append(new_chord)\n",
        "  #if sequence is note\n",
        "  else:\n",
        "    new_n = note.Note(sequence)\n",
        "    new_n.offset = offset\n",
        "    new_n.storedInstrument = instrument.Piano()\n",
        "    output_notes.append(new_n)\n",
        "    \n",
        "  offset += 0.5\n",
        "\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp='AI_ongaku.mid')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}